{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG_3tS9cz1H_"
      },
      "source": [
        "# Object Detection with RetinaNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOA8B4JTz1IC"
      },
      "source": [
        "# Retinanet github clone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xmltodict\n",
        "!rm -rf retinanet\n",
        "!git clone https://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@github.com/pai-plznw4me/retinanet"
      ],
      "metadata": {
        "id": "nAt_4rqqkAWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 가루쌀 데이터 다운로드"
      ],
      "metadata": {
        "id": "ZMCG8ddrmKIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/retinanet; python main_rice_data_download.py"
      ],
      "metadata": {
        "id": "l6hghbITksy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 인코딩"
      ],
      "metadata": {
        "id": "lq4iZIxAmN3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/retinanet; python main_generate_datasets.py"
      ],
      "metadata": {
        "id": "lmc1Z-eomAIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습"
      ],
      "metadata": {
        "id": "B5cw5uvCmhlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.join(os.getcwd(), 'retinanet'))"
      ],
      "metadata": {
        "id": "N9T-qbwICyg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from loss import RetinaNetLoss\n",
        "from retinanet import retinanet\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# 모델 저장 장소\n",
        "model_dir = os.path.join(os.getcwd(), 'retinanet', 'sample_data', 'Riceseedlingdetection', 'Encode', 'retinanet')\n",
        "\n",
        "# set hparam\n",
        "num_classes = 2\n",
        "batch_size = 2\n",
        "\n",
        "# set lr\n",
        "learning_rates = [2.5e-06, 0.000625, 0.00125, 0.0025, 0.00025, 2.5e-05]\n",
        "learning_rate_boundaries = [125, 250, 500, 240000, 360000]\n",
        "learning_rate_fn = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    boundaries=learning_rate_boundaries, values=learning_rates\n",
        ")\n",
        "\n",
        "# set model\n",
        "resnet50_backbone = retinanet.get_backbone()\n",
        "loss_fn = RetinaNetLoss(num_classes)\n",
        "model = retinanet.RetinaNet(num_classes, resnet50_backbone)\n",
        "\n",
        "# set optimizer\n",
        "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=learning_rate_fn, momentum=0.9)\n",
        "model.compile(loss=loss_fn, optimizer=optimizer)\n",
        "\n",
        "# set os callback\n",
        "callbacks_list = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(model_dir, \"weights\" + \"_epoch_{epoch}\"),\n",
        "        monitor=\"loss\",\n",
        "        save_best_only=False,\n",
        "        save_weights_only=True,\n",
        "        verbose=1,\n",
        "    )\n",
        "]\n",
        "\n",
        "# training\n",
        "save_encode_dir = os.path.join(os.getcwd(), 'retinanet', 'sample_data', 'Riceseedlingdetection', 'Encode')\n",
        "xs = np.load(os.path.join(save_encode_dir, 'preproc_resnet_images.npy'))\n",
        "ys = np.load(os.path.join(save_encode_dir, 'labels.npy'))\n",
        "\n",
        "print('xs shape : {}'.format(xs.shape))\n",
        "print('ys shape : {}'.format(ys.shape))\n",
        "epochs = 1"
      ],
      "metadata": {
        "id": "vWFyO4kgCCWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "for i in range(epochs):\n",
        "    max_data= 600\n",
        "    index = np.arange(600)\n",
        "    index=index[:max_data]\n",
        "    np.random.shuffle(index)\n",
        "    shuffle_xs = xs[index]\n",
        "    shuffle_ys = ys[index]\n",
        "    model.fit(\n",
        "        shuffle_xs[:max_data],\n",
        "        shuffle_ys[:max_data],\n",
        "        batch_size=3,\n",
        "        epochs=epochs,\n",
        "        callbacks=callbacks_list,\n",
        "        verbose=1,\n",
        "    )"
      ],
      "metadata": {
        "id": "WneVhO6bo5ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Phu_-P-Ez1IP"
      },
      "source": [
        "## Building inference model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from decode import DecodePredictions, decode_box_predictions\n",
        "from anchor import AnchorBox\n",
        "from coordinate import convert_to_corners\n",
        "from visualize import visualize_bboxes"
      ],
      "metadata": {
        "id": "uo-IUOSz20Bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_box_predictions(anchor_boxes, box_predictions):\n",
        "    box_variance=[0.1, 0.1, 0.2, 0.2],\n",
        "    boxes = box_predictions * box_variance\n",
        "    boxes = tf.concat(\n",
        "        [\n",
        "            boxes[..., :2] * anchor_boxes[..., 2:] + anchor_boxes[..., :2],\n",
        "            tf.cast(tf.math.exp(boxes[..., 2:]), tf.float32) * anchor_boxes[..., 2:],\n",
        "        ],\n",
        "        axis=-1,\n",
        "    )\n",
        "    boxes_transformed = convert_to_corners(boxes)\n",
        "    return boxes_transformed\n"
      ],
      "metadata": {
        "id": "ogSSSq5v3V7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "weights_dir = model_dir\n",
        "latest_checkpoint = tf.train.latest_checkpoint(weights_dir)\n",
        "model.load_weights(latest_checkpoint)"
      ],
      "metadata": {
        "id": "4NyKeEg2226k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inference data\n",
        "y_hat = model.predict(xs[0:1])[0]\n",
        "y_hat_oht = y_hat[..., 4:]\n",
        "y_hat_reg = y_hat[..., :4]\n",
        "y_hat_cls = np.argmax(y_hat_oht, axis=-1).squeeze()\n",
        "y_hat_pos_reg = y_hat_reg[0][y_hat_cls]\n",
        "print('postive : {}'.format(np.sum(y_hat_cls)))\n",
        "\n",
        "# ground dataset\n",
        "ys_cls = ys[..., 4:][0]\n",
        "ys_pos_mask = (ys_cls == 1).squeeze()\n",
        "ys_reg = ys[..., :4][0]\n",
        "print('postive : {}'.format(np.sum(ys_pos_mask)))"
      ],
      "metadata": {
        "id": "6lCC-UKv1aNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-pqOuIoz1IP"
      },
      "outputs": [],
      "source": [
        "# generate anchor\n",
        "anchor_box = AnchorBox()\n",
        "anchor_boxes = anchor_box.get_anchors(640, 640)\n",
        "print(anchor_boxes.shape)\n",
        "print(y_hat_reg.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decode\n",
        "bbox_hat_xyxy = decode_box_predictions(anchor_boxes, y_hat_reg)\n",
        "bbox_gnd_xyxy = decode_box_predictions(anchor_boxes, ys_reg)\n",
        "pos_bbox_gnd_xyxy = bbox_gnd_xyxy[ys_pos_mask]"
      ],
      "metadata": {
        "id": "XfzdRt7KQ2tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ground dataset\n",
        "visualize_bboxes(xs[0].astype(int), pos_bbox_gnd_xyxy)\n",
        "\n",
        "# predict visualize\n",
        "visualize_bboxes(xs[0].astype(int), pos_bbox_hat[:])\n"
      ],
      "metadata": {
        "id": "s8av9WgH3F4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfuUuHMwz1IP"
      },
      "source": [
        "## Generating detections"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nms(bboxes, classes, nms_iou_threshold=0.5):\n",
        "    confidence_threshold=0.05\n",
        "    nms_iou_threshold=0.5\n",
        "    max_detections_per_class=100\n",
        "    max_detections=100\n",
        "    scores = y_hat_cls\n",
        "\n",
        "    nms_classes = tf.image.non_max_suppression(\n",
        "        bboxes,\n",
        "        classes,\n",
        "        max_output_size=100,\n",
        "        iou_threshold=0.01,\n",
        "        score_threshold=float('-inf'),\n",
        "        name=None\n",
        "    )\n",
        "    nms_bboxes = pos_bbox_hat[nms_index, :]\n",
        "    return nms_bboxes, nms_classes"
      ],
      "metadata": {
        "id": "-FnED-jl0IO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_bbox_nms_hat, pos_bbox_nms_cls = nms(bbox_hat_xyxy, y_hat_cls)"
      ],
      "metadata": {
        "id": "aAGQK2B67GNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize\n",
        "visualize_bboxes(xs[0].astype(int), pos_bbox_nms_hat)"
      ],
      "metadata": {
        "id": "pruoLEGt5lLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6th3iMnp6Rcr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}